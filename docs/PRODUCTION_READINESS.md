# Production Readiness - Warmup & √âvolution Progressive

## ‚úÖ Warmup - √âtat Actuel

### Syst√®me de Warmup Existant (COMPLET)

Vous avez **D√âJ√Ä** un syst√®me de warmup professionnel dans `app/services/warmup_engine.py`:

#### Caract√©ristiques du WarmupEngine

```python
‚úÖ Progression sur 6 semaines
‚úÖ Quotas progressifs configurables (.env)
‚úÖ V√©rification des taux de bounce (< 5%)
‚úÖ V√©rification des taux de spam (< 0.1%)
‚úÖ Pause automatique si seuils d√©pass√©s
‚úÖ Reprise automatique apr√®s p√©riode de pause
‚úÖ Stats quotidiennes (sent, delivered, bounced, complaints, opens, clicks)
‚úÖ Alertes Telegram en cas de probl√®me
‚úÖ Passage automatique WARMING ‚Üí ACTIVE
```

#### Configuration Actuelle (.env)

```env
WARMUP_WEEK1_QUOTA=50         # Semaine 1: 50/jour
WARMUP_WEEK2_QUOTA=200        # Semaine 2: 200/jour
WARMUP_WEEK3_QUOTA=500        # Semaine 3: 500/jour
WARMUP_WEEK4_QUOTA=1500       # Semaine 4: 1500/jour
WARMUP_WEEK5_QUOTA=5000       # Semaine 5: 5000/jour
WARMUP_WEEK6_QUOTA=10000      # Semaine 6: 10000/jour
WARMUP_MAX_BOUNCE_RATE=5.0    # Max 5% bounces
WARMUP_MAX_SPAM_RATE=0.1      # Max 0.1% complaints
```

### ‚ö†Ô∏è PROBL√àME IDENTIFI√â

**Le warmup engine N'EST PAS utilis√© dans la t√¢che Celery!**

Dans `src/infrastructure/background/tasks.py`, la fonction `advance_warmup_task()` a une **logique simplifi√©e** avec un TODO:

```python
# TODO: Implement proper advancement logic from warmup_engine service
current_phase = warmup_plan.phase
current_quota = warmup_plan.current_daily_quota

# Simple advancement: double quota if < target
if current_quota < warmup_plan.target_daily_quota:
    new_quota = min(current_quota * 2, warmup_plan.target_daily_quota)
```

**Cette logique est INCORRECTE pour la production!**

---

## üîß Corrections N√©cessaires pour Production

### 1. Int√©grer WarmupEngine dans la t√¢che Celery (PRIORIT√â 1)

**Fichier √† corriger**: `src/infrastructure/background/tasks.py`

```python
@celery_app.task(name="src.infrastructure.background.tasks.advance_warmup_task")
def advance_warmup_task() -> dict:
    """
    Advance IP warmup (periodic task - daily).
    Uses the professional WarmupEngine from app.services.warmup_engine
    """
    import asyncio
    from app.database import SessionLocal
    from app.services.warmup_engine import WarmupEngine

    db = SessionLocal()
    try:
        # Create engine
        engine = WarmupEngine(db)

        # Run daily tick (async)
        loop = asyncio.get_event_loop()
        loop.run_until_complete(engine.daily_tick())

        return {"success": True, "message": "Warmup advanced successfully"}

    except Exception as e:
        db.rollback()
        return {"success": False, "error": str(e)}
    finally:
        db.close()
```

### 2. Enregistrer les Stats Quotidiennes (PRIORIT√â 1)

**Nouveau fichier**: `src/infrastructure/background/tasks.py` (ajouter)

```python
@celery_app.task(name="src.infrastructure.background.tasks.record_warmup_stats_task")
def record_warmup_stats_task(ip_id: int, stats: dict) -> dict:
    """
    Record daily warmup stats for an IP.

    Args:
        ip_id: IP ID
        stats: {
            "sent": 50,
            "delivered": 48,
            "bounced": 2,
            "complaints": 0,
            "opens": 25,
            "clicks": 10
        }
    """
    from app.database import SessionLocal
    from app.models import IP, WarmupPlan
    from app.services.warmup_engine import WarmupEngine

    db = SessionLocal()
    try:
        ip = db.query(IP).filter_by(id=ip_id).first()
        if not ip or not ip.warmup_plan:
            return {"success": False, "error": "IP or warmup plan not found"}

        engine = WarmupEngine(db)
        stat = engine.record_daily_stats(
            plan=ip.warmup_plan,
            sent=stats.get("sent", 0),
            delivered=stats.get("delivered", 0),
            bounced=stats.get("bounced", 0),
            complaints=stats.get("complaints", 0),
            opens=stats.get("opens", 0),
            clicks=stats.get("clicks", 0),
        )

        return {"success": True, "stat_id": stat.id}

    except Exception as e:
        db.rollback()
        return {"success": False, "error": str(e)}
    finally:
        db.close()
```

### 3. Configurer Celery Beat (PRIORIT√â 1)

**Fichier √† cr√©er/modifier**: `src/infrastructure/background/celery_app.py`

```python
from celery.schedules import crontab

celery_app.conf.beat_schedule = {
    'advance-warmup-daily': {
        'task': 'src.infrastructure.background.tasks.advance_warmup_task',
        'schedule': crontab(hour=1, minute=0),  # Tous les jours √† 1h du matin
    },
}
```

### 4. Webhooks ‚Üí Warmup Stats (PRIORIT√â 2)

**Fichier √† modifier**: `src/presentation/api/v2/webhooks.py`

Quand vous recevez des √©v√©nements MailWizz/PowerMTA, il faut **agr√©ger les stats quotidiennes** et les enregistrer pour le warmup:

```python
# Dans mailwizz_webhook() et powermta_webhook()
# Apr√®s avoir cr√©√© l'√©v√©nement, v√©rifier si l'IP est en warmup

from app.models import IP

# Retrouver l'IP qui a envoy√© l'email (via metadata)
ip_address = metadata.get("sending_ip")  # √Ä r√©cup√©rer depuis PowerMTA
if ip_address:
    ip = db.query(IP).filter(IP.address == ip_address, IP.status == "warming").first()
    if ip and ip.warmup_plan:
        # Incr√©menter les compteurs quotidiens dans Redis
        from src.infrastructure.cache import get_cache
        cache = get_cache()

        today = datetime.utcnow().date().isoformat()
        key = f"warmup:ip:{ip.id}:date:{today}"

        if event_type == EventType.DELIVERED:
            cache.increment(f"{key}:delivered")
        elif event_type == EventType.BOUNCED:
            cache.increment(f"{key}:bounced")
        elif event_type == EventType.COMPLAINED:
            cache.increment(f"{key}:complaints")
        elif event_type == EventType.OPENED:
            cache.increment(f"{key}:opens")
        elif event_type == EventType.CLICKED:
            cache.increment(f"{key}:clicks")
```

### 5. T√¢che de Consolidation Quotidienne (PRIORIT√â 2)

**Nouveau endpoint**: T√¢che Celery qui consolide les stats Redis ‚Üí PostgreSQL chaque jour

```python
@celery_app.task(name="src.infrastructure.background.tasks.consolidate_warmup_stats_task")
def consolidate_warmup_stats_task() -> dict:
    """
    Consolidate Redis warmup counters to PostgreSQL (runs daily).

    Reads all warmup:ip:*:date:* keys from Redis and saves to WarmupDailyStat.
    """
    from app.database import SessionLocal
    from app.models import IP
    from app.services.warmup_engine import WarmupEngine
    from src.infrastructure.cache import get_cache
    from datetime import datetime, timedelta

    db = SessionLocal()
    cache = get_cache()

    try:
        # Get all warming IPs
        warming_ips = db.query(IP).filter(IP.status == "warming").all()

        yesterday = (datetime.utcnow() - timedelta(days=1)).date().isoformat()

        for ip in warming_ips:
            if not ip.warmup_plan:
                continue

            key_prefix = f"warmup:ip:{ip.id}:date:{yesterday}"

            sent = cache.get(f"{key_prefix}:sent") or 0
            delivered = cache.get(f"{key_prefix}:delivered") or 0
            bounced = cache.get(f"{key_prefix}:bounced") or 0
            complaints = cache.get(f"{key_prefix}:complaints") or 0
            opens = cache.get(f"{key_prefix}:opens") or 0
            clicks = cache.get(f"{key_prefix}:clicks") or 0

            if sent > 0:  # Only record if there was activity
                engine = WarmupEngine(db)
                engine.record_daily_stats(
                    plan=ip.warmup_plan,
                    sent=sent,
                    delivered=delivered,
                    bounced=bounced,
                    complaints=complaints,
                    opens=opens,
                    clicks=clicks,
                )

                # Delete Redis keys after consolidation
                cache.delete_pattern(f"{key_prefix}:*")

        return {"success": True, "ips_processed": len(warming_ips)}

    except Exception as e:
        db.rollback()
        return {"success": False, "error": str(e)}
    finally:
        db.close()


# Ajouter au beat_schedule:
celery_app.conf.beat_schedule['consolidate-warmup-stats'] = {
    'task': 'src.infrastructure.background.tasks.consolidate_warmup_stats_task',
    'schedule': crontab(hour=0, minute=30),  # Tous les jours √† 0h30
}
```

---

## üìà √âvolution Progressive: 5 Domaines ‚Üí 50+ Domaines

### Strat√©gie Recommand√©e

#### Phase 1: D√©marrage avec 5 Domaines (Semaines 1-6)

```python
# Seed initial
tenant = SOS-Expat (id=1)
domains = [
    "mail1.sos-mail.com",
    "mail2.sos-mail.com",
    "mail3.sos-mail.com",
    "mail4.sos-mail.com",
    "mail5.sos-mail.com",
]
ips = [
    "45.123.10.1",  # mail1
    "45.123.10.2",  # mail2
    "45.123.10.3",  # mail3
    "45.123.10.4",  # mail4
    "45.123.10.5",  # mail5
]

# Warmup: 1 IP/domaine par semaine (rotation)
Week 1: Warm IP 45.123.10.1 (mail1.sos-mail.com)
Week 2: Warm IP 45.123.10.2 (mail2.sos-mail.com) + continue IP1
Week 3: Warm IP 45.123.10.3 (mail3.sos-mail.com) + continue IP1-2
Week 4: Warm IP 45.123.10.4 (mail4.sos-mail.com) + continue IP1-3
Week 5: Warm IP 45.123.10.5 (mail5.sos-mail.com) + continue IP1-4
Week 6: All 5 IPs in warmup, IP1 becomes ACTIVE
```

#### Phase 2: Ajout Progressif (Semaines 7-42)

**R√®gle**: Ajouter **1 nouveau domaine/IP par semaine** max

```python
# Script: scripts/add_domain.py

def add_new_domain_with_ip(tenant_id: int, domain_name: str, ip_address: str):
    """
    Add a new domain + IP and start warmup.

    Usage:
        python scripts/add_domain.py --tenant 1 --domain mail6.sos-mail.com --ip 45.123.10.6
    """
    from app.database import SessionLocal
    from app.models import Domain, IP, WarmupPlan
    from app.enums import DomainStatus, IPStatus, WarmupPhase
    from app.services.warmup_engine import WarmupEngine

    db = SessionLocal()
    try:
        # 1. Create domain
        domain = Domain(
            tenant_id=tenant_id,
            domain=domain_name,
            status=DomainStatus.WARMING.value,
        )
        db.add(domain)
        db.flush()

        # 2. Create IP
        ip = IP(
            tenant_id=tenant_id,
            address=ip_address,
            domain_id=domain.id,
            status=IPStatus.WARMING.value,
            weight=0,  # Will be 100 after warmup
        )
        db.add(ip)
        db.flush()

        # 3. Create warmup plan
        engine = WarmupEngine(db)
        plan = engine.create_plan(ip)

        db.commit()

        print(f"‚úÖ Domain {domain_name} + IP {ip_address} created and warmup started")
        print(f"   - Warmup Phase: {plan.phase}")
        print(f"   - Daily Quota: {plan.current_daily_quota}")
        print(f"   - Target: {plan.target_daily_quota}/day in 6 weeks")

    except Exception as e:
        db.rollback()
        print(f"‚ùå Error: {e}")
    finally:
        db.close()
```

**Utilisation**:

```bash
# Semaine 7: Ajouter 6√®me domaine
docker-compose exec api python scripts/add_domain.py \
  --tenant 1 \
  --domain mail6.sos-mail.com \
  --ip 45.123.10.6

# Semaine 8: Ajouter 7√®me domaine
docker-compose exec api python scripts/add_domain.py \
  --tenant 1 \
  --domain mail7.sos-mail.com \
  --ip 45.123.10.7

# etc...
```

#### Phase 3: Monitoring de la Mont√©e en Charge

**API Endpoint pour surveiller la progression**:

```bash
# Voir tous les domaines/IPs en warmup
curl http://localhost:8000/api/v1/warmup

# Response:
{
  "warming_ips": [
    {
      "ip": "45.123.10.1",
      "domain": "mail1.sos-mail.com",
      "phase": "completed",
      "status": "active",
      "daily_quota": 10000,
      "warmup_duration_days": 42
    },
    {
      "ip": "45.123.10.6",
      "domain": "mail6.sos-mail.com",
      "phase": "week_2",
      "status": "warming",
      "daily_quota": 200,
      "warmup_duration_days": 14
    }
  ],
  "active_ips": 5,
  "warming_ips": 1,
  "total_daily_capacity": 50200  # 5√ó10000 + 1√ó200
}
```

---

## üö® Ce qui Manque pour Production Ready

### CRITIQUES (Bloquer le d√©ploiement)

1. **‚ùå Warmup Engine non connect√© √† Celery**
   - Statut: TODO dans le code
   - Impact: Warmup ne fonctionne pas correctement
   - Solution: Voir corrections ci-dessus
   - Temps: 2-3 heures

2. **‚ùå Stats quotidiennes non enregistr√©es**
   - Statut: Pas de consolidation Redis ‚Üí PostgreSQL
   - Impact: Pas de tracking du warmup
   - Solution: T√¢che `consolidate_warmup_stats_task`
   - Temps: 1-2 heures

3. **‚ùå Webhooks ne trackent pas les IPs en warmup**
   - Statut: √âv√©nements cr√©√©s mais pas li√©s au warmup
   - Impact: Pas de donn√©es pour avancer les phases
   - Solution: Modifier webhooks pour incr√©menter Redis
   - Temps: 2-3 heures

### IMPORTANTES (D√©ployer mais surveiller)

4. **‚ö†Ô∏è Alertes Telegram non test√©es**
   - Statut: Code existe mais pas de `TELEGRAM_BOT_TOKEN` en .env
   - Impact: Pas d'alertes en cas de probl√®me warmup
   - Solution: Configurer bot Telegram
   - Temps: 30 minutes

5. **‚ö†Ô∏è Pas de dashboard warmup visuel**
   - Statut: API existe mais pas de frontend
   - Impact: Monitoring via API seulement
   - Solution: Cr√©er page React simple
   - Temps: 4-6 heures (optionnel)

6. **‚ö†Ô∏è PowerMTA config non g√©n√©r√©e automatiquement**
   - Statut: Service existe mais pas appel√©
   - Impact: Configuration manuelle n√©cessaire
   - Solution: Endpoint pour g√©n√©rer config
   - Temps: 1 heure

### NICE-TO-HAVE (Post-lancement)

7. **üí° Tests end-to-end warmup**
   - Statut: Pas de tests automatis√©s
   - Impact: Risque de r√©gressions
   - Solution: Suite de tests pytest
   - Temps: 4-6 heures

8. **üí° Simulation de warmup (mode test)**
   - Statut: N'existe pas
   - Impact: Impossible de tester sans vrais envois
   - Solution: Mode dry-run
   - Temps: 2-3 heures

9. **üí° Rollback automatique en cas d'√©chec**
   - Statut: Pause existe mais pas de rollback
   - Impact: Manual intervention n√©cessaire
   - Solution: Auto-rollback √† phase pr√©c√©dente
   - Temps: 3-4 heures

---

## ‚úÖ Plan d'Action Production

### Sprint 1 (Avant Production) - 1 jour

```
‚úÖ Int√©grer WarmupEngine dans advance_warmup_task (3h)
‚úÖ Cr√©er consolidate_warmup_stats_task (2h)
‚úÖ Modifier webhooks pour tracker warmup (3h)
‚úÖ Configurer Telegram bot (30min)
‚úÖ Cr√©er script add_domain.py (1h)
‚úÖ Tests manuels du warmup (2h)

TOTAL: ~11h30 (1 journ√©e de travail)
```

### Sprint 2 (Post-Production) - 2 jours

```
‚ö†Ô∏è Endpoint pour g√©n√©rer PowerMTA config (1h)
‚ö†Ô∏è Dashboard warmup simple (6h)
‚ö†Ô∏è Tests end-to-end (6h)
‚ö†Ô∏è Documentation utilisateur (2h)

TOTAL: ~15h (2 jours de travail)
```

### Sprint 3 (Optimisation) - 1 jour

```
üí° Mode simulation/dry-run (3h)
üí° Rollback automatique (4h)
üí° Monitoring Prometheus/Grafana (4h)

TOTAL: ~11h (1 jour de travail)
```

---

## üìù Checklist Production

### Avant D√©ploiement

- [ ] Corriger `advance_warmup_task` avec WarmupEngine
- [ ] Cr√©er `consolidate_warmup_stats_task`
- [ ] Modifier webhooks pour tracker warmup
- [ ] Configurer Celery Beat schedule
- [ ] Configurer `TELEGRAM_BOT_TOKEN` + `TELEGRAM_CHAT_ID`
- [ ] Cr√©er `scripts/add_domain.py`
- [ ] Tester warmup sur 1 IP pendant 7 jours
- [ ] Configurer quotas warmup dans .env
- [ ] Configurer seuils bounce/spam dans .env

### Premier Jour de Production

- [ ] D√©marrer avec 1 seul domaine/IP
- [ ] V√©rifier quotas respect√©s (50 emails/jour)
- [ ] V√©rifier stats dans PostgreSQL
- [ ] V√©rifier alertes Telegram
- [ ] Surveiller taux de bounce (< 5%)
- [ ] Surveiller taux de spam (< 0.1%)

### Premi√®re Semaine

- [ ] Ajouter 1 nouveau domaine/IP par jour (5 total)
- [ ] V√©rifier avancement automatique des phases
- [ ] Monitorer capacit√© totale quotidienne
- [ ] Ajuster quotas si n√©cessaire

### Apr√®s 6 Semaines

- [ ] Tous les 5 premiers IPs devraient √™tre ACTIVE
- [ ] Capacit√©: 5 √ó 10,000 = 50,000 emails/jour
- [ ] Commencer √† ajouter 1 nouveau domaine/semaine
- [ ] Objectif: 50 domaines en 1 an

---

## üéØ R√©sum√©

### ‚úÖ Ce qui est D√âJ√Ä bien fait

- Architecture compl√®te (Clean Architecture)
- WarmupEngine professionnel avec toutes les features
- Gestion multi-tenant parfaite
- Syst√®me de pause/reprise automatique
- Alertes configur√©es
- Stats tracking pr√©vu
- √âvolution progressive possible

### ‚ùå Ce qui DOIT √™tre corrig√© (BLOQUANT)

1. Connecter WarmupEngine √† la t√¢che Celery
2. Cr√©er la consolidation des stats Redis ‚Üí PostgreSQL
3. Modifier les webhooks pour tracker les IPs en warmup

**Temps total: ~8 heures de travail**

### √âvolution 5 ‚Üí 50+ domaines

**Strat√©gie valid√©e**:
- Semaines 1-5: Warmup 5 premiers domaines (1/semaine)
- Semaines 6-42: 5 IPs actifs + warmup progressif
- Semaines 7+: Ajouter 1 nouveau domaine/semaine max
- Ann√©e 1: 50 domaines op√©rationnels
- Monitoring continu avec API + alertes Telegram

**Capacit√© finale**: 50 domaines √ó 10,000 emails/jour = **500,000 emails/jour**

---

Voulez-vous que je cr√©e les scripts de correction maintenant pour rendre le warmup production-ready?
